#    ______     ______     __   __     ______   __     ______
#   /\  ___\   /\  __ \   /\ "-.\ \   /\  ___\ /\ \   /\  ___\
#   \ \ \____  \ \ \/\ \  \ \ \-.  \  \ \  __\ \ \ \  \ \ \__ \
#    \ \_____\  \ \_____\  \ \_\\"\_\  \ \_\    \ \_\  \ \_____\
#     \/_____/   \/_____/   \/_/ \/_/   \/_/     \/_/   \/_____/
#
# This is an example configuration file for the LLMCheck tool complete with explanations.
# Start from here whenever possible.

# LLM Configurations
# Here it is plainly litellm style. You must leave out no fields.
# As a example, here is OPENAI gpt-4o-mini as both evaluator and evaluatee:
# evaluator:
#   model_name: "gpt-4o-mini"
#   api_base: "https://api.openai.com/v1"
#   temperature: 0.6
# evaluatee:
#   model_name: "gpt-4o-mini"
#   api_base: "https://api.openai.com/v1"
#   temperature: 0.6

# Here is the vllm new token limit:
llm_max_new_tokens: 4096

# Here is a vllm setup:
evaluator:
  # model_name: "hosted_vllm/meta-llama/Llama-3.1-8B-Instruct"
  model_name: "ollama_chat/llama3.1:8b-instruct-fp16"
  # model_name: "openai/gpt-4o-mini"
  # api_base: "http://localhost:8000/v1"
  api_base: "http://localhost:11434"
  # api_base: "https://api.openai.com/v1"
  temperature: 0.6
evaluatee:
  # model_name: "hosted_vllm/meta-llama/Llama-3.1-8B-Instruct"
  model_name: "ollama_chat/llama3.1:8b-instruct-fp16"
  # api_base: "http://localhost:8000/v1"
  api_base: "http://localhost:11434"
  temperature: 0.6

# Embedding Model Configurations
## Option 1. OpenAI API
similarity_config:
  type: "api"
  model_name: "text-embedding-ada-002"
  api_base: "https://api.openai.com/v1"
## Option 2. Huggingface Transformers (PyTorch, local)
# similarity_config:
#   type: "huggingface"
#   model_name: "google-bert/bert-base-uncased"
#   device: "cuda"

# Experiment Configurations
## max depth of the self-consistency tree
max_depth: 2
## number of operations to be applied to the input.
# if you provide more operations than this number, the evaluator will only consider the first n operations.
n_operations: 2

# Overrides, OPTIONAL
# if you provide a root, it will override the root generated by the evaluator model.
# root: "Artificial intelligence enhances the efficiency of various industries by automating tasks, analyzing data, and providing insights for better decision-making."

# if you provide a list of operations, it will override the operations generated by the evaluator model.
# operations:
#   - ["replace all nouns with synonyms", "replace all synonyms with the original nouns"]
#   - ["convert to passive voice", "convert back to active voice"]
#   - ["remove all adjectives", "restore the eliminated adjectives"]

# constraint to generate root using evalutor model.
constraints: |
  Write a LeetCode-Hard style problem. The problem must be super hard, and very novel 
  in concept and implementation. It should not be previously seen in any LeetCode problem.
  The answer need to have 100-120 lines.  
  Concepts the problem must include:
  - Algorithmic Techniques: Require techniques such as dynamic programming (DP), backtracking, divide-and-conquer, or graph algorithms (e.g., shortest paths, flow networks).
  - Concurrency and Asynchronous Computation: Introduce elements like multithreading, asynchronous I/O, or task scheduling.
  - Mathematical Foundations: Leverage number theory (e.g., modular arithmetic, prime factorization), geometry (e.g., computational geometry), or probability/statistics.
  - Recursive and Functional Programming: Include deep recursion, memoization, or higher-order functions.
  - Edge Case Robustness: Test the solver’s ability to handle extreme edge cases, such as large inputs, high levels of recursion, or adversarial inputs designed to break naive solutions.

  Please do this in a function way, e.g. provide a function called "main"
  that returns the intended answer.
  You will have to provide this in YAML format, comprising of multiple
  keys and values:
  - "description": a brief description of the question. It should be
                  a string. As all LeetCode problems do, it should have
                  a title, a description, example inputs and outputs, 
                  just like what you see in the LeetCode website.
                  It is a string. Write it in markdown format.
  - "code": the code that is the solution to the problem. It should be
           a function called "main" that returns the intended answer.
           It should be in `python3` language. Start without a code block.
           Its "main" function takes in a list of parameters, as the input for
           one test case.
           It is a string.
  - "programming_language": the programming language used in the code.
                            In this case, it should be "python3".
                            It is a string.
  - "inputs": the inputs that tests its functionality. It is a list of
              dictionaries for the kwargs of the function, the test case 
              for evaluating an solution, which will put into the "main" function 
              to obtain the output. You will need 20 test cases. The keys
              should be parameters of the "main" function, not "args".or "kwargs"!
              If your "main" is "def main(a, b, c):", then the keys should be
              "a", "b", "c". It should consist of edge cases only that are super 
              easy to fail.
  Please use the "|" to write multi line strings:
  description: |
    ...
    ...
  code: |
    def main(*args):
        ...
        ...
  programming_language: "python3"
  inputs:
    - {"somekey": "somevalue", "anotherkey": "anothervalue", ...}
    ...
    ...

  Please start right away without any explanation. Please DO NOT put it in a code block.
  Please follow all the instructions or it will crash.
  You must have a "main" function in the code, or it will crash. 
  Use correct identation or it will crash.
  In "inputs" do not use [1] * 100 to write a list; use [1, 1, 1, 1, 1, 1, 1, 1, 1, 1] instead (e.g. write out each element).
prompt_template: |
  Generate {n_operations} pairs of **extremely difficult transform-reverse operations** for testing language model consistency.
  Ensure that these operations are applicable to the **main function** in the `code` key of the root code: "{root_code}".
  Each operation must significantly alter the implementation while preserving its functionality, and the reverse operation must restore the code to its original form. These transformations must test the model's ability to handle complex, nuanced changes and edge cases, **without relying on external libraries beyond Python's standard library**.

  Format each line as: "transform operation | reverse operation"

  **Examples**:
  - "Transform the recursion in the `main` function into an iterative approach using an explicit stack and state-tracking mechanisms | Revert the iterative implementation back to the original recursive logic."
  - "Refactor the `main` function to handle computations via generators and lazy evaluation, minimizing memory usage for large datasets | Replace generators and lazy evaluation with direct, eager computation for simplicity."
  - "Replace the nested loops in the `main` function with a divide-and-conquer strategy, ensuring equivalent results | Revert the divide-and-conquer approach back to nested loops."
  - "Change the data structure used in the `main` function from a list to a dictionary with key-based lookups for optimization | Revert the dictionary back to a list while ensuring functionality remains intact."

  **Instructions**:
  1. Transformations must introduce **conceptual and implementation challenges**, such as:
     - Switching between algorithmic paradigms (e.g., recursion ↔ iteration, greedy ↔ divide-and-conquer).
     - Leveraging advanced concepts in Python's standard library (e.g., `collections`, `itertools`, `heapq`, `functools`).
     - Rewriting code to handle edge cases explicitly or implicitly.
     - Changing data structures or introducing intermediate transformations.
     - Refactoring functions into alternative logic flows or modular components.
  2. Each operation must test the model's ability to:
     - Handle drastic code transformations without losing correctness.
     - Preserve edge case functionality and maintain logical equivalence.
     - Implement and reverse non-trivial changes reliably.
  3. Avoid trivial or superficial operations, such as changes to formatting, comments, or variable names.

  **Examples of Hard Transformations**:
  - "Convert all iterations in the `main` function into functional programming constructs using `map`, `filter`, and `reduce` | Revert functional constructs back to explicit loops for clarity."
  - "Refactor the `main` function to perform all data processing using priority queues implemented with `heapq` | Revert the priority queue-based implementation back to simpler structures like lists or dictionaries."
  - "Replace any use of global state in the `main` function with explicitly passed parameters, ensuring the function is entirely stateless | Reintroduce the global state back into the function for simplicity."
  - "Introduce memoization using Python's `functools.lru_cache` decorator to optimize recursive calls in the `main` function | Remove the memoization and revert to the original implementation without caching."
  - "Implement the logic in the `main` function using state machines, explicitly modeling transitions for key operations | Revert the state machine representation back to direct control structures like loops and conditionals."

  **Output Format**:
  ```yaml
  operations:
    - "transform operation | reverse operation"
    - "transform operation | reverse operation"
    ...

  
operation_code_format_enforce_prompt: |
  For the sake of parsing, please enclose your code within a code block,
  e.g. f"```{programming_language}\n{code}\n```". Please make sure that the code is valid.
  And programming_language is the language for the code. For python code, it should be "python3".
  For JavaScript code, it should be "javascript", etc. Do NOT include anything else.

# evaluation parameters
# "1" stands for L-1 AVG Similarity: the average similarity between direct parent-child node pairs
# "2" stands for L-2 AVG Similarity: the average similarity between grandparent-parent-child node triplets
# ...
distance: [1, 2, 3, 5]
