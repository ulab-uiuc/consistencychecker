# these will feed into litellm
# please specify api keys (if needed) with environment variables
evaluator:
  model_name: "gpt-4o-mini"
  api_base: "https://api.openai.com/v1"
target:
  model_name: "ollama/llama3.1:8b-instruct-q8_0"
  api_base: "http://localhost:11434"
similarity_config:
  type: "api"
  model_name: "text-embedding-ada-002"
  api_base: "https://api.openai.com/v1"

# this uses huggingface's transformers library
# similarity_config:
#   type: "huggingface"
#   model_name: "google-bert/bert-base-uncased"
#   device: "cuda"

# sadly however, ollama does not currently provide openai-like embedding apis;
# or I will have the huggingface/torch access mode removed just use apis instead

# max depth of the self-consistency tree
max_depth: 4

# number of operations to be applied to the input.
# if you provide more operations than this number, the evaluator will only consider the first n operations.
n_operations: 2

# constraint to generate root using evalutor model.
constraints: "Write a simple sentence about artificial intelligence in 20 words."

# optional
# if you provide a root, it will override the root generated by the evaluator model.
root: "Artificial intelligence enhances the efficiency of various industries by automating tasks, analyzing data, and providing insights for better decision-making."

# optional
# if you provide a list of operations, it will override the operations generated by the evaluator model.
operations:
  - ["replace all nouns with synonyms", "replace all synonyms with the original nouns"]
  - ["convert to passive voice", "convert back to active voice"]
  - ["remove all adjectives", "restore the eliminated adjectives"]

# evaluation parameters
# "1" stands for L-1 AVG Similarity: the average similarity between direct parent-child node pairs
# "2" stands for L-2 AVG Similarity: the average similarity between grandparent-parent-child node triplets
# ...
distance: [1, 2, 3, 5]
