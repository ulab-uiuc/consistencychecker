#    ______     ______     __   __     ______   __     ______
#   /\  ___\   /\  __ \   /\ "-.\ \   /\  ___\ /\ \   /\  ___\
#   \ \ \____  \ \ \/\ \  \ \ \-.  \  \ \  __\ \ \ \  \ \ \__ \
#    \ \_____\  \ \_____\  \ \_\\"\_\  \ \_\    \ \_\  \ \_____\
#     \/_____/   \/_____/   \/_/ \/_/   \/_/     \/_/   \/_____/
#
# This is an example configuration file for the LLMCheck tool complete with explanations.
# Start from here whenever possible.

# LLM Configurations
# Here it is plainly litellm style. You must leave out no fields.
# As a example, here is OPENAI gpt-4o-mini as both evaluator and evaluatee:
# evaluator:
#   model_name: "gpt-4o-mini"
#   api_base: "https://api.openai.com/v1"
#   temperature: 0.6
# evaluatee:
#   model_name: "gpt-4o-mini"
#   api_base: "https://api.openai.com/v1"
#   temperature: 0.6

# Here is the vllm new token limit:
llm_max_new_tokens: 4096

# Here is max retry limit for tree building
retry_max: 16

# Here is the time limit for execution of the code given one input.
time_limit: 2.0

# Here is a vllm setup:
evaluator:
  # model_name: "hosted_vllm/meta-llama/Llama-3.1-8B-Instruct"
  model_name: "ollama_chat/llama3.1:8b-instruct-fp16"
  # model_name: "openai/gpt-4o-mini"
  # api_base: "http://localhost:8000/v1"
  api_base: "http://localhost:11434"
  # api_base: "https://api.openai.com/v1"
  temperature: 0.6
evaluatee:
  # model_name: "hosted_vllm/meta-llama/Llama-3.1-8B-Instruct"
  model_name: "ollama_chat/llama3.1:8b-instruct-fp16"
  # api_base: "http://localhost:8000/v1"
  api_base: "http://localhost:11434"
  temperature: 0.6

# Embedding Model Configurations
## Option 1. OpenAI API
similarity_config:
  type: "api"
  model_name: "text-embedding-ada-002"
  api_base: "https://api.openai.com/v1"
## Option 2. Huggingface Transformers (PyTorch, local)
# similarity_config:
#   type: "huggingface"
#   model_name: "google-bert/bert-base-uncased"
#   device: "cuda"

# Experiment Configurations
## max depth of the self-consistency tree
max_depth: 3
## number of operations to be applied to the input.
# if you provide more operations than this number, the evaluator will only consider the first n operations.
n_operations: 3

# Overrides, OPTIONAL
# if you provide a root, it will override the root generated by the evaluator model.
# root: "Artificial intelligence enhances the efficiency of various industries by automating tasks, analyzing data, and providing insights for better decision-making."

# if you provide a list of operations, it will override the operations generated by the evaluator model.
# operations:
#   - ["replace all nouns with synonyms", "replace all synonyms with the original nouns"]
#   - ["convert to passive voice", "convert back to active voice"]
#   - ["remove all adjectives", "restore the eliminated adjectives"]

# constraint to generate root using evalutor model.
constraints: |
  Write a 400 word, complicated English paragraph that might appear on a
  news website.
  Please do this in a function way, e.g. provide a function called "main"
  that returns the content as a string.
  You will have to provide this in YAML format, comprising of multiple
  keys and values:
  - "description": a brief description of what the paragraph is about. This is
                   purely for debugging.
  - "code": the code that is the solution to the problem. It should be
           a function called "main" that returns the intended answer.
           It should be in `python3` language.
  - "programming_language": the programming language used in the code.
                            In this case, it should be "python3".
                            It is a string.
  - "inputs": the inputs that tests its functionality. It is a list of
              dictionaries for the kwargs of the function, the test case
              for evaluating an solution, which will put into the "main" function
              to obtain the output. Since the main function does not take any
              arguments, it should be a list with one empty dictionary.
  Please use the "|" to write multi line strings:
  description: |
    ...
    ...
  code: |
    def main():
        ...
        ...
  programming_language: "python3"
  inputs:
    - {}

  Please start right away without any explanation. Please DO NOT put it in a code block.
  Please follow all the instructions or it will crash.
  You must have a "main" function in the code, or it will crash.
  Use correct identation or it will crash.
  In "inputs" do not use [1] * 100 to write a list; use [1, 1, 1, 1, 1, 1, 1, 1, 1, 1] instead (e.g. write out each element).
prompt_template: |
  Generate {n_operations} pairs of translation and reverse translation operations for the following code.
  Ensure that these operations are applicable to the **main function** in the `code` key of the root code: "{root_code}".

  Format each line as: "transform operation | reverse operation"
  Please translate to a random language other than English, and then back to English, to ensure that the operations are clear and unambiguous.
  For example: "translate what 'main' returns to Japanese | translate the Japanese return value in 'main' back to English"
  These operations should NOT leak out information about the code itself.
  **Output Format**:
  ```yaml
  operations:
    - "transform operation | reverse operation"
    - "transform operation | reverse operation"
    ...


operation_code_format_enforce_prompt: |
  For the sake of parsing, please enclose your code within a code block,
  e.g. f"```{programming_language}\n{code}\n```". Please make sure that the code is valid.
  And programming_language is the language for the code. For python code, it should be "python3".
  For JavaScript code, it should be "javascript", etc. Do NOT include anything else.
  This is a translation task, so you should directly translate the return value and
  replace the return value with the translated value. Do NOT attempt to import translation
  libraries or use any external resources. The code should be self-contained.

# evaluation parameters
# "1" stands for L-1 AVG Similarity: the average similarity between direct parent-child node pairs
# "2" stands for L-2 AVG Similarity: the average similarity between grandparent-parent-child node triplets
# ...
distance: [1, 2, 3, 5]
